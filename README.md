# LLM performance Benchmark test Tool

[![Python Version](https://img.shields.io/badge/python-3.7%2B-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

ä¸€ä¸ªé«˜æ€§èƒ½å¼‚æ­¥LLMæœåŠ¡å‹æµ‹å·¥å…·ï¼Œæ”¯æŒæµå¼å“åº”åˆ†æå’Œè¯¦ç»†æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡ï¼ŒLLM performance Benchmark test Tool.
A Python script for benchmarking LLM serving performance under different concurrency levels using asynchronous requests. Provides detailed metrics and visualizations.

## åŠŸèƒ½ç‰¹æ€§

âœ… **å¤šç»´åº¦æ€§èƒ½æŒ‡æ ‡**  
- é¦–Tokenæ—¶é—´ï¼ˆTTFTï¼‰
- Tokenè¾“å‡ºé€Ÿç‡ï¼ˆTOPTï¼‰
- è¾“å…¥/è¾“å‡ºTokensååé‡
- è¯·æ±‚æˆåŠŸç‡ç»Ÿè®¡
- åˆ†ä½æ•°ç»Ÿè®¡ï¼ˆP95ç­‰ï¼‰

ğŸ“Š **æµ‹è¯•æŠ¥å‘Š**  
- æ ‡å‡†ç»Ÿè®¡æŒ‡æ ‡ï¼ˆå‡å€¼/æ ‡å‡†å·®ï¼‰
- è¯¦ç»†è€—æ—¶åˆ†æ

## ä½¿ç”¨åœºæ™¯

- æ¨¡å‹æœåŠ¡å‹åŠ›æµ‹è¯•
- APIæ€§èƒ½åŸºå‡†æµ‹è¯•


## å¿«é€Ÿå¼€å§‹
é…ç½®æµ‹è¯•å‚æ•° (ä¿®æ”¹main()å‡½æ•°)
```bash
    base_url = "http://xxx:8000/v1"
    model = "Qwen/QwQ-32B"
    num_requests = 100
    concurrency_levels = [10,20,30,40,50]
```
### å®‰è£…ä¾èµ–
```bash
pip install openai asyncio tabulate matplotlib
```

æŸ¥çœ‹ç»“æœ:

æ–‡æœ¬æŠ¥å‘Š: benchmark_results.txt

å¯è§†åŒ–å›¾è¡¨: benchmark_chart.png

![dsad ](img_1.png)
![dsad ](benchmark_chart.png)